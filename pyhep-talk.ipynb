{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4322f8a5-29d3-4d9a-afaf-f532ff06e246",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# <br> Up your ML game \n",
    "![title](levelup.jpg)\n",
    "## PyHEP DEV \n",
    "### Liv V\u00e5ge 28.10.2025 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b7542",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why this talk?\n",
    "\n",
    "The ML ecosystem changes **faster than your average PhD**. \n",
    "\n",
    "By the time you finish reading the PyTorch docs, three new frameworks have been released and LLMs are writing better code than you.\n",
    "\n",
    "**Goal:** Help you navigate the chaos and pick the right tools without spending 6 months on Stack Overflow.\n",
    "\n",
    "---\n",
    "\n",
    "## What we'll cover:\n",
    "1. **ML Frameworks** - PyTorch, JAX, Keras, etc. (which one and why?)\n",
    "2. **Workflow Tools** - W&B, MLflow, Optuna (stop using print statements)\n",
    "3. **Training & Deployment** - hls4ml, ONNX, HTCondor (get off your laptop)\n",
    "4. **HEP-ML Bridge** - uproot, awkward, hist (because ROOT files aren't going anywhere)\n",
    "5. **Industry Tools** - What industry does better (and what we can steal)\n",
    "6. **Fun Shortcuts** - LLMs, Hugging Face, and other \"cheats\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa4ca5-3ac3-4f48-ab73-c3fba7f1c676",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Common ML Frameworks\n",
    "\n",
    "## The eternal question: Which framework should I use?\n",
    "\n",
    "**Short answer:** PyTorch (probably)\n",
    "\n",
    "**Long answer:** Let's actually compare them... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b85136",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Quick Framework Comparison\n",
    "\n",
    "| Framework | Best For | Pros | Cons |\n",
    "|-----------|----------|------|------|\n",
    "| **PyTorch** | Research, flexibility, HEP | Pythonic, great debugging, huge community | Verbose, more boilerplate |\n",
    "| **PyTorch Lightning** | Production, clean code | Organized, less boilerplate, built-in best practices | Another abstraction to learn |\n",
    "| **JAX** | Speed demons, researchers | FAST, functional programming, auto-vectorization | Functional paradigm learning curve |\n",
    "| **Keras** | Beginners, quick prototypes | Super simple API, fast to start | Less flexibility, slower development |\n",
    "| **Scikit-learn** | Classical ML, baselines | Easy, stable, great docs | Not for deep learning |\n",
    "| **XGBoost** | Tabular data, structured features | Fast, interpretable, great for HEP kinematics | Not for complex deep learning |\n",
    "\n",
    "**Decision tree:**\n",
    "- Just starting? \u2192 **Keras** or **Scikit-learn**\n",
    "- Need a quick baseline on tabular data? \u2192 **XGBoost** or **Scikit-learn**\n",
    "- Working with HEP kinematic features? \u2192 **XGBoost** (often best!)\n",
    "- Doing research/custom architectures? \u2192 **PyTorch**\n",
    "- Want cleaner code? \u2192 **PyTorch Lightning**\n",
    "- Need maximum speed? \u2192 **JAX**\n",
    "- Working in a team? \u2192 **PyTorch** or **PyTorch Lightning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d97bf35f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (1000, 4), Labels: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Quick demo: Same simple neural network in different frameworks\n",
    "import numpy as np\n",
    "\n",
    "# Generate some fake HEP-like data (4 kinematic features)\n",
    "np.random.seed(42)\n",
    "X_train = np.random.randn(1000, 4).astype(np.float32)\n",
    "y_train = (X_train[:, 0] + X_train[:, 1] > 0).astype(np.float32)\n",
    "X_test = np.random.randn(200, 4).astype(np.float32)\n",
    "y_test = (X_test[:, 0] + X_test[:, 1] > 0).astype(np.float32)\n",
    "\n",
    "print(f\"Training data: {X_train.shape}, Labels: {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456bf70d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Option 1: PyTorch (the verbose way)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83af14e8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7555\n",
      "Epoch 5, Loss: 0.7462\n",
      "\u2705 PyTorch training done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Define model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Setup\n",
    "model = SimpleNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_t = torch.from_numpy(X_train)\n",
    "y_train_t = torch.from_numpy(y_train).unsqueeze(1)\n",
    "\n",
    "# Training loop (the part everyone copy-pastes)\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_t)\n",
    "    loss = criterion(outputs, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"\u2705 PyTorch training done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7957b656",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Option 2: Scikit-learn (the \"I just want it to work\" way)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a760b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.980\n",
      "\u2705 Scikit-learn: 3 lines and done. Beginners rejoice!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# That's it. Literally.\n",
    "clf = MLPClassifier(hidden_layer_sizes=(16,), max_iter=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(\"\u2705 Scikit-learn: 3 lines and done. Beginners rejoice!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509d747",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Option 3: PyTorch Lightning (the \"I want my code to not be a mess\" way)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925bb3b9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udca1 Lightning = PyTorch + Organization + Built-in Best Practices\n"
     ]
    }
   ],
   "source": [
    "# Commented out - install if you want to run:\n",
    "# !pip install pytorch-lightning\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "#\n",
    "# class LitModel(pl.LightningModule):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Linear(4, 16), nn.ReLU(), nn.Linear(16, 1), nn.Sigmoid()\n",
    "#         )\n",
    "#     \n",
    "#     def forward(self, x):\n",
    "#         return self.layers(x)\n",
    "#     \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         y_hat = self(x)\n",
    "#         loss = nn.BCELoss()(y_hat, y)\n",
    "#         self.log('train_loss', loss)\n",
    "#         return loss\n",
    "#     \n",
    "#     def configure_optimizers(self):\n",
    "#         return optim.Adam(self.parameters(), lr=0.001)\n",
    "#\n",
    "# # Automatic logging, checkpointing, multi-GPU support, etc.\n",
    "# # trainer = pl.Trainer(max_epochs=10)\n",
    "# # trainer.fit(model, train_dataloader)\n",
    "\n",
    "print(\"\ud83d\udca1 Lightning = PyTorch + Organization + Built-in Best Practices\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47452bd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### JAX: For when you need SPEED\n",
    "\n",
    "JAX is functional programming meets deep learning. It's fast. Really fast.\n",
    "\n",
    "**Key features:**\n",
    "- `jax.jit` - Just-In-Time compilation (makes code go brrrr)\n",
    "- `jax.grad` - Automatic differentiation of anything\n",
    "- `jax.vmap` - Auto-vectorization\n",
    "- Works on GPU/TPU with zero code changes\n",
    "\n",
    "**Warning:** You have to think differently (functional programming, immutability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb1f66",
   "metadata": {},
   "source": [
    "### XGBoost: The Gradient Boosting Powerhouse\n",
    "\n",
    "**What it is:** Extreme Gradient Boosting - tree-based ensemble method\n",
    "\n",
    "**Why it matters for HEP:**\n",
    "- Handles tabular data exceptionally well (which HEP has lots of!)\n",
    "- Often outperforms neural networks on structured data\n",
    "- Interpretable (feature importance, SHAP values)\n",
    "- Fast training and inference\n",
    "- Great baseline before trying deep learning\n",
    "\n",
    "**When to use:**\n",
    "- Tabular data with many features\n",
    "- Need quick, interpretable results\n",
    "- Want feature importance\n",
    "- Limited training data available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b22462",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# XGBoost example\n",
    "# Uncomment if you have xgboost installed\n",
    "# !pip install xgboost\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    # Train XGBoost\n",
    "    clf_xgb = xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "    clf_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_xgb = clf_xgb.predict(X_test)\n",
    "    acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    print(f\"XGBoost Accuracy: {acc_xgb:.3f}\")\n",
    "    \n",
    "    # Show feature importance\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    for i, imp in enumerate(clf_xgb.feature_importances_):\n",
    "        print(f\"  Feature {i}: {imp:.3f}\")\n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "    print(\"\\nXGBoost is great for:\")\n",
    "    print(\"- Tabular/structured data\")\n",
    "    print(\"- Quick benchmarks\")\n",
    "    print(\"- Understanding feature importance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ab310",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 1-to-1 Comparison: Timing and Accuracy\n",
    "\n",
    "Let's see how different frameworks perform on the exact same data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f1da6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fp/5tqzs2jn7fgbdzfwyp_qjkmr0000gn/T/ipykernel_85393/579065664.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Display results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Framework'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Time (s)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Framework Comparison Results:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m\\nFastest: \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Framework'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m (\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time (s)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m.3f\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34ms)\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7185\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7186\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7187\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7189\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7191\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Time'"
     ]
    }
   ],
   "source": [
    "# Comprehensive comparison of frameworks\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "# Test PyTorch\n",
    "start = time.time()\n",
    "model = SimpleNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "X_train_t = torch.from_numpy(X_train)\n",
    "y_train_t = torch.from_numpy(y_train).unsqueeze(1)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_t)\n",
    "    loss = criterion(outputs, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_t = torch.from_numpy(X_test)\n",
    "    predictions = model(X_test_t).numpy().flatten() > 0.5\n",
    "    acc = (predictions == y_test).mean()\n",
    "\n",
    "pytorch_time = time.time() - start\n",
    "results.append(('PyTorch', pytorch_time, acc))\n",
    "\n",
    "# Test Scikit-learn\n",
    "start = time.time()\n",
    "clf_skl = MLPClassifier(hidden_layer_sizes=(16,), max_iter=100, random_state=42)\n",
    "clf_skl.fit(X_train, y_train)\n",
    "acc_skl = clf_skl.score(X_test, y_test)\n",
    "sklearn_time = time.time() - start\n",
    "results.append(('Scikit-learn', sklearn_time, acc_skl))\n",
    "\n",
    "# Test XGBoost (if available)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    start = time.time()\n",
    "    clf_xgb = xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss', verbosity=0)\n",
    "    clf_xgb.fit(X_train, y_train)\n",
    "    acc_xgb = clf_xgb.score(X_test, y_test)\n",
    "    xgb_time = time.time() - start\n",
    "    results.append(('XGBoost', xgb_time, acc_xgb))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Display results\n",
    "df = pd.DataFrame(results, columns=['Framework', 'Time (s)', 'Accuracy'])\n",
    "df = df.sort_values('Time (s)')\n",
    "print(\"Framework Comparison Results:\\n\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nFastest: {df.iloc[0]['Framework']} ({df.iloc[0]['Time (s)']:.3f}s)\")\n",
    "print(f\"Most Accurate: {df.loc[df['Accuracy'].idxmax(), 'Framework']} ({df['Accuracy'].max():.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1012d2a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u26a1 JAX can be 10-100x faster for some operations\n",
      "\ud83d\udcda Good resources: JAX docs, Google Colab tutorials\n"
     ]
    }
   ],
   "source": [
    "# JAX quick demo - speed comparison\n",
    "# Commented out - install jax if you want to run\n",
    "\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# from jax import jit, grad\n",
    "# import time\n",
    "#\n",
    "# # Regular function\n",
    "# def slow_function(x):\n",
    "#     return jnp.sum(x ** 2)\n",
    "#\n",
    "# # JIT-compiled version (fast!)\n",
    "# fast_function = jit(slow_function)\n",
    "#\n",
    "# x = jnp.ones((10000,))\n",
    "# \n",
    "# # First call compiles, subsequent calls are FAST\n",
    "# %timeit slow_function(x).block_until_ready()\n",
    "# %timeit fast_function(x).block_until_ready()\n",
    "\n",
    "print(\"\u26a1 JAX can be 10-100x faster for some operations\")\n",
    "print(\"\ud83d\udcda Good resources: JAX docs, Google Colab tutorials\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab61407-4775-4d69-92fd-7ef7caf05197",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# ML Workflow Tools\n",
    "\n",
    "## Stop using `print()` for everything!\n",
    "\n",
    "You know you've done this:\n",
    "```python\n",
    "print(f\"Epoch {epoch}, loss: {loss}, acc: {acc}, lr: {lr}, ...\")\n",
    "# *scrolls through terminal for 10 minutes*\n",
    "```\n",
    "\n",
    "**There's a better way.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b957acc7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Weights & Biases (W&B) - The Gold Standard\n",
    "\n",
    "**What it does:**\n",
    "- Automatic logging of metrics, hyperparameters, system info\n",
    "- Beautiful dashboards\n",
    "- Experiment comparison\n",
    "- Model versioning\n",
    "- Artifact tracking\n",
    "- **Free for academics!**\n",
    "\n",
    "**When to use:** Any serious project. Just use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4278a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# W&B Quick Start (commented - needs account)\n",
    "# !pip install wandb\n",
    "\n",
    "# import wandb\n",
    "#\n",
    "# # Initialize\n",
    "# wandb.init(project=\"pyhep-demo\", name=\"experiment-1\")\n",
    "#\n",
    "# # Log whatever you want\n",
    "# for epoch in range(10):\n",
    "#     loss = 1.0 / (epoch + 1)  # fake loss\n",
    "#     wandb.log({\"loss\": loss, \"epoch\": epoch})\n",
    "#\n",
    "# # Log your model, datasets, anything!\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"\ud83c\udfa8 W&B gives you beautiful dashboards without the matplotlib pain\")\n",
    "print(\"\ud83d\udca1 Pro tip: wandb.watch(model) tracks gradients automatically!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f73e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MLflow - The Open Source Alternative\n",
    "\n",
    "**Pros:**\n",
    "- Fully open source\n",
    "- Self-hosted (for the privacy-conscious)\n",
    "- Experiment tracking + model registry\n",
    "- Works with any ML library\n",
    "\n",
    "**Cons:**\n",
    "- Less pretty than W&B\n",
    "- Need to host it yourself\n",
    "- Smaller community\n",
    "\n",
    "**When to use:** You need full control, can't/won't use cloud services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2305c32",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# MLflow example\n",
    "# import mlflow\n",
    "#\n",
    "# mlflow.start_run()\n",
    "# mlflow.log_param(\"learning_rate\", 0.001)\n",
    "# mlflow.log_metric(\"accuracy\", 0.95)\n",
    "# mlflow.log_artifact(\"model.pth\")\n",
    "# mlflow.end_run()\n",
    "\n",
    "print(\"\ud83c\udfe0 MLflow: Great for on-premise setups\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4145b4d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Optuna - Hyperparameter Optimization Made Easy\n",
    "\n",
    "**Stop doing grid search in 2025!**\n",
    "\n",
    "Optuna uses smart algorithms (TPE, CMA-ES) to find good hyperparameters faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfad9ee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Optuna example - hyperparameter tuning\n",
    "# !pip install optuna\n",
    "\n",
    "# import optuna\n",
    "#\n",
    "# def objective(trial):\n",
    "#     # Suggest hyperparameters\n",
    "#     lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "#     n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "#     \n",
    "#     # Train your model with these hyperparameters\n",
    "#     # ... training code ...\n",
    "#     # accuracy = train_and_evaluate(lr, n_layers)\n",
    "#     \n",
    "#     # Return metric to optimize\n",
    "#     # return accuracy\n",
    "#     return 0.95  # dummy\n",
    "#\n",
    "# # Optimize!\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=100)\n",
    "#\n",
    "# print(f\"Best params: {study.best_params}\")\n",
    "\n",
    "print(\"\ud83c\udfaf Optuna: Smarter than grid search, easier than manual tuning\")\n",
    "print(\"\ud83d\udca1 Integrates with W&B, PyTorch Lightning, etc.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c633b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Workflow Tools: Quick Comparison\n",
    "\n",
    "| Tool | Best For | Setup Difficulty | Cost |\n",
    "|------|----------|------------------|------|\n",
    "| **W&B** | Everything | Easy | Free (academic) |\n",
    "| **MLflow** | On-premise, privacy | Medium | Free (self-host) |\n",
    "| **Optuna** | Hyperparameter tuning | Easy | Free |\n",
    "| **b-hive** | CERN users | Easy | Free (CERN) |\n",
    "\n",
    "**Pro tip:** Use W&B + Optuna together. They integrate perfectly!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b38b8-b5f0-421b-b889-21ef300dfc03",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Model Training & Deployment\n",
    "\n",
    "## Get off your laptop!\n",
    "\n",
    "Your MacBook is crying. Let's talk about scaling up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e845930a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### HTCondor - The HEP Classic\n",
    "\n",
    "**What it is:** Distributed computing system used at CERN and beyond\n",
    "\n",
    "**Pros:**\n",
    "- Already set up at most HEP institutions\n",
    "- Handle thousands of jobs\n",
    "- Free (for you)\n",
    "\n",
    "**Cons:**\n",
    "- Not designed for ML (but works!)\n",
    "- Can be slow to start\n",
    "- Queue times vary\n",
    "\n",
    "**When to use:** You're at a HEP institution and need to run many jobs\n",
    "\n",
    "```bash\n",
    "# Example HTCondor submit file\n",
    "# universe = vanilla\n",
    "# executable = train_model.sh\n",
    "# arguments = --learning-rate 0.001\n",
    "# queue 100 # Submit 100 jobs!\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e003e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SWAN - CERN's Jupyter Hub\n",
    "\n",
    "**What it is:** Cloud-based Jupyter notebooks at CERN\n",
    "\n",
    "**Pros:**\n",
    "- Access to CERN data\n",
    "- Pre-configured environment\n",
    "- Spark integration\n",
    "- GPUs available\n",
    "\n",
    "**When to use:** You're at CERN and want to prototype quickly\n",
    "\n",
    "**URL:** https://swan.cern.ch/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ac86b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ONNX - Make your model portable\n",
    "\n",
    "**Problem:** Trained in PyTorch, but production uses TensorFlow (or C++, or...)\n",
    "\n",
    "**Solution:** ONNX (Open Neural Network Exchange)\n",
    "\n",
    "**What it does:**\n",
    "- Convert models between frameworks\n",
    "- Optimize for inference\n",
    "- Deploy anywhere (edge devices, web, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5fa78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# ONNX Example - Export PyTorch model\n",
    "# import torch.onnx\n",
    "#\n",
    "# # Your trained PyTorch model\n",
    "# dummy_input = torch.randn(1, 4)\n",
    "# torch.onnx.export(model, dummy_input, \"model.onnx\")\n",
    "#\n",
    "# # Now use it in other frameworks!\n",
    "# import onnxruntime as ort\n",
    "# session = ort.InferenceSession(\"model.onnx\")\n",
    "# result = session.run(None, {\"input\": X_test[:1]})\n",
    "\n",
    "print(\"\ud83d\udce6 ONNX: Train anywhere, deploy everywhere\")\n",
    "print(\"\ud83c\udfaf Especially useful for edge deployment and production\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7471a7f2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### hls4ml - ML on FPGAs\n",
    "\n",
    "**The coolest HEP-specific tool you didn't know you needed**\n",
    "\n",
    "**Problem:** You need ultra-low latency inference (< 1 microsecond) for triggers\n",
    "\n",
    "**Solution:** hls4ml converts your neural network to FPGA firmware\n",
    "\n",
    "**Use cases:**\n",
    "- LHC trigger systems\n",
    "- Real-time event selection\n",
    "- Anything requiring hardware acceleration\n",
    "\n",
    "```python\n",
    "# import hls4ml\n",
    "# config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "# hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "# model, hls_config=config, output_dir='my-hls-test'\n",
    "# )\n",
    "# hls_model.compile()\n",
    "```\n",
    "\n",
    "**Mind-blowing:** Your Python model \u2192 Hardware in < 1 hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8fa14b-f23f-462e-bf46-a43031c639d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# HEP-ML Bridge Tools\n",
    "\n",
    "## The \"ROOT files aren't going anywhere\" section\n",
    "\n",
    "You can't do ML without data. In HEP, that means ROOT files, weird event structures, and ragged arrays.\n",
    "\n",
    "**These tools save your sanity:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28845a9e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### uproot - Read ROOT files without ROOT\n",
    "\n",
    "**The game changer.**\n",
    "\n",
    "Before: Install ROOT, fight with Python bindings, cry \n",
    "After: `pip install uproot`, read files with pandas-like syntax\n",
    "\n",
    "**No C++ dependencies. No ROOT installation. Pure Python bliss.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41985ec8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# uproot example (without actual ROOT file)\n",
    "# import uproot\n",
    "#\n",
    "# # Read ROOT file\n",
    "# file = uproot.open(\"data.root\")\n",
    "# tree = file[\"Events\"]\n",
    "#\n",
    "# # Get branches as arrays\n",
    "# pt = tree[\"jet_pt\"].array()\n",
    "# eta = tree[\"jet_eta\"].array()\n",
    "#\n",
    "# # Or as pandas DataFrame\n",
    "# df = tree.arrays([\"jet_pt\", \"jet_eta\", \"jet_phi\"], library=\"pd\")\n",
    "\n",
    "print(\"\ud83c\udf89 uproot: Because life's too short to compile ROOT\")\n",
    "print(\"\ud83d\udca1 Works with awkward, numpy, pandas, and more!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a15c30",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Awkward Array - Handle Jagged Data\n",
    "\n",
    "**Problem:** HEP events have variable-length lists (jets, tracks, etc.)\n",
    "\n",
    "**Standard approach:** Pad everything, waste memory, write ugly code\n",
    "\n",
    "**Awkward Array:** Numpy for jagged/nested/variable-length data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf10d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "\n",
    "# Events with variable numbers of jets\n",
    "events = ak.Array([\n",
    "    {\"jets\": [{\"pt\": 50, \"eta\": 0.1}, {\"pt\": 30, \"eta\": -0.5}]},  # 2 jets\n",
    "    {\"jets\": [{\"pt\": 100, \"eta\": 1.2}]},                           # 1 jet\n",
    "    {\"jets\": [{\"pt\": 40, \"eta\": 0.3}, {\"pt\": 35, \"eta\": 0.8}, {\"pt\": 25, \"eta\": -1.0}]}  # 3 jets\n",
    "])\n",
    "\n",
    "# Operations work naturally on jagged data!\n",
    "jet_pts = events.jets.pt\n",
    "print(\"Jet pts:\", jet_pts)\n",
    "\n",
    "# Calculate things per event\n",
    "leading_jet_pt = ak.max(events.jets.pt, axis=1)\n",
    "print(\"Leading jet pt per event:\", leading_jet_pt)\n",
    "\n",
    "# Slice like numpy\n",
    "high_pt_jets = events.jets[events.jets.pt > 35]\n",
    "print(\"High-pt jets:\", high_pt_jets)\n",
    "\n",
    "print(\"\\n\u2728 Awkward: No more padding! No more for-loops!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dbdec7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### hist - Modern Histogramming\n",
    "\n",
    "**ROOT's TH1/TH2 are... showing their age.**\n",
    "\n",
    "`hist` is a modern, Pythonic histogramming library:\n",
    "- Clean syntax\n",
    "- Integrates with numpy, awkward\n",
    "- Beautiful plotting with matplotlib/mplhep\n",
    "- Type hints, named axes, units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888e3ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Modern histogramming with hist\n",
    "# !pip install hist\n",
    "\n",
    "# from hist import Hist\n",
    "# import hist\n",
    "#\n",
    "# # Create histogram with named axes\n",
    "# h = Hist.new.Reg(50, 0, 200, name=\"pt\", label=\"$p_T$ [GeV]\").Double()\n",
    "# h.fill(pt=np.random.exponential(50, 10000))\n",
    "#\n",
    "# # Plot (works with matplotlib)\n",
    "# import matplotlib.pyplot as plt\n",
    "# h.plot()\n",
    "# plt.show()\n",
    "\n",
    "print(\"\ud83d\udcca hist: Histograms that don't make you want to cry\")\n",
    "print(\"\ud83d\udca1 Named axes, units, better plotting. Just better.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33d953",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Complete HEP-ML Pipeline\n",
    "\n",
    "```python\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "from hist import Hist\n",
    "\n",
    "# 1. Read ROOT file\n",
    "with uproot.open(\"data.root:Events\") as tree:\n",
    " events = tree.arrays([\"jet_*\"], library=\"ak\")\n",
    "\n",
    "# 2. Process with awkward\n",
    "good_events = events[ak.num(events.jet_pt) >= 2]\n",
    "leading_jets = good_events.jet_pt[:, 0]\n",
    "\n",
    "# 3. Make histograms\n",
    "h = Hist.new.Reg(50, 0, 200, name=\"pt\").Double()\n",
    "h.fill(leading_jets)\n",
    "\n",
    "# 4. Convert to ML format\n",
    "X = ak.to_numpy(ak.pad_none(events.jet_pt, 5, clip=True))\n",
    "# Now feed to PyTorch/JAX/etc!\n",
    "```\n",
    "\n",
    "**The dream: ROOT file \u2192 ML model in < 50 lines**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6089f22a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Industry Tools\n",
    "\n",
    "## What industry does better (and what we can steal)\n",
    "\n",
    "HEP is amazing at physics. Industry is amazing at software engineering.\n",
    "\n",
    "**Let's learn from them:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172abf4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Testing & Linting - Stop Breaking Things\n",
    "\n",
    "**Industry:** Comprehensive tests, CI/CD, code review, linting \n",
    "**HEP:** \"It worked on my machine\" \n",
    "\n",
    "**Tools you should use:**\n",
    "\n",
    "1. **pytest** - Testing framework\n",
    "2. **black** - Code formatter (stop arguing about formatting)\n",
    "3. **ruff** - Fast linter\n",
    "4. **mypy** - Type checking\n",
    "5. **pre-commit** - Run checks before committing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b890eb7d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Quick testing example\n",
    "# tests/test_model.py\n",
    "\n",
    "# import pytest\n",
    "# import torch\n",
    "#\n",
    "# def test_model_output_shape():\n",
    "#     model = SimpleNN()\n",
    "#     x = torch.randn(10, 4)\n",
    "#     output = model(x)\n",
    "#     assert output.shape == (10, 1), \"Wrong output shape!\"\n",
    "#\n",
    "# def test_model_output_range():\n",
    "#     model = SimpleNN()\n",
    "#     x = torch.randn(10, 4)\n",
    "#     output = model(x)\n",
    "#     assert torch.all(output >= 0) and torch.all(output <= 1), \"Sigmoid broken!\"\n",
    "\n",
    "print(\"\u2705 Write tests. Your future self will thank you.\")\n",
    "print(\"\ud83d\udca1 Pro tip: Test your preprocessing! That's where most bugs hide.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45416b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### GitHub Actions - Automate Everything\n",
    "\n",
    "**Stop manually running tests. Let robots do it.**\n",
    "\n",
    "Example `.github/workflows/test.yml`:\n",
    "```yaml\n",
    "name: Tests\n",
    "on: [push, pull_request]\n",
    "jobs:\n",
    " test:\n",
    " runs-on: ubuntu-latest\n",
    " steps:\n",
    " - uses: actions/checkout@v3\n",
    " - uses: actions/setup-python@v4\n",
    " with:\n",
    " python-version: '3.10'\n",
    " - run: pip install -r requirements.txt\n",
    " - run: pytest\n",
    " - run: ruff check .\n",
    "```\n",
    "\n",
    "**Now every commit is automatically tested. Magic!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f2e4f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AWS SageMaker - When You Need Industrial Scale\n",
    "\n",
    "**What it is:** AWS's ML platform (training, deployment, everything)\n",
    "\n",
    "**Pros:**\n",
    "- Scales to infinity\n",
    "- Managed infrastructure\n",
    "- Production-ready deployment\n",
    "- AutoML features\n",
    "\n",
    "**Cons:**\n",
    "- Costs money (sometimes a lot)\n",
    "- Learning curve\n",
    "- Vendor lock-in\n",
    "\n",
    "**When to use:** \n",
    "- You need serious scale\n",
    "- You have budget\n",
    "- Production deployment\n",
    "\n",
    "**HEP alternative:** Usually HTCondor + custom scripts (cheaper, less polished)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5473c5e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What HEP Can Learn from Industry\n",
    "\n",
    "| Practice | Industry | HEP | What to do |\n",
    "|----------|----------|-----|-----------|\n",
    "| **Testing** | Comprehensive | Sparse | Write pytest tests! |\n",
    "| **CI/CD** | GitHub Actions | Manual | Add GitHub Actions |\n",
    "| **Code Review** | Required | Optional | Make PRs mandatory |\n",
    "| **Documentation** | Detailed | \"See code\" | Write docstrings |\n",
    "| **Versioning** | Semantic | Git SHA | Use proper versions |\n",
    "| **Linting** | Enforced | What's that? | Use ruff/black |\n",
    "\n",
    "**Bottom line:** Treat your code like a product, not a script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec2a2b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fun Shortcuts & \"Cheats\"\n",
    "\n",
    "## Work smarter, not harder\n",
    "\n",
    "The secret sauce. The shortcuts your supervisor doesn't want you to know about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec254bce",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1. Make LLMs Do Your Work\n",
    "\n",
    "**Let's be honest:** We're all using ChatGPT/Claude/Copilot\n",
    "\n",
    "**Good uses:**\n",
    "- Boilerplate code (data loaders, training loops)\n",
    "- Documentation and docstrings\n",
    "- Bug finding\n",
    "- Code explanation\n",
    "- Unit test generation\n",
    "\n",
    "**Bad uses:**\n",
    "- Novel research code (they hallucinate)\n",
    "- Critical analysis code (verify everything!)\n",
    "- Anything you don't understand\n",
    "\n",
    "**Pro tips:**\n",
    "- Be specific: \"Write a PyTorch data loader for awkward arrays\"\n",
    "- Iterate: Start simple, add complexity\n",
    "- **Always understand the code it gives you**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a37f22",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Example: Let's ask an LLM to write a custom loss function\n",
    "# Prompt: \"Write a PyTorch loss function that combines binary cross entropy with a custom regularization term\"\n",
    "\n",
    "# LLM output (cleaned up):\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, reg_weight=0.01):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.reg_weight = reg_weight\n",
    "    \n",
    "    def forward(self, predictions, targets, model_params):\n",
    "        bce_loss = self.bce(predictions, targets)\n",
    "        # L2 regularization\n",
    "        reg_loss = sum(p.pow(2.0).sum() for p in model_params)\n",
    "        return bce_loss + self.reg_weight * reg_loss\n",
    "\n",
    "print(\"\ud83e\udd16 LLMs: Your 24/7 coding assistant\")\n",
    "print(\"\u26a0\ufe0f  But verify everything! They confidently hallucinate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83e18d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2. Steal from Hugging Face\n",
    "\n",
    "**Hugging Face:** GitHub for ML models\n",
    "\n",
    "**What's there:**\n",
    "- 500,000+ pre-trained models\n",
    "- Datasets\n",
    "- Code examples\n",
    "- Entire pipelines\n",
    "\n",
    "**You can:**\n",
    "- Fine-tune existing models (faster than training from scratch)\n",
    "- Use pre-trained embeddings\n",
    "- Copy architectures\n",
    "- Download datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7335c43",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hugging Face example - Use a pre-trained model\n",
    "# !pip install transformers\n",
    "\n",
    "# from transformers import pipeline\n",
    "#\n",
    "# # Use a pre-trained model with ONE line\n",
    "# classifier = pipeline(\"sentiment-analysis\")\n",
    "# result = classifier(\"The LHC is amazing!\")\n",
    "# print(result)\n",
    "\n",
    "# For HEP: Look for:\n",
    "# - Transformer models for jet tagging\n",
    "# - Graph neural networks\n",
    "# - Anomaly detection models\n",
    "\n",
    "print(\"\ud83e\udd17 Hugging Face: Don't reinvent the wheel, fine-tune it!\")\n",
    "print(\"\ud83d\udca1 Search for 'particle physics', 'HEP', 'jet tagging' on HF\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde11e7c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3. Quick Prototyping Tricks\n",
    "\n",
    "**Trick 1: Use `fastai` for rapid prototyping**\n",
    "- High-level API (even simpler than Keras)\n",
    "- Best practices built-in\n",
    "- Great for quick experiments\n",
    "\n",
    "**Trick 2: `torchinfo` for model debugging**\n",
    "```python\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(1, 4))\n",
    "# Instantly see: layers, params, output shapes\n",
    "```\n",
    "\n",
    "**Trick 3: `einops` for tensor operations**\n",
    "```python\n",
    "from einops import rearrange, reduce\n",
    "# No more confusing reshapes!\n",
    "x = rearrange(x, 'b c h w -> b (c h w)')\n",
    "```\n",
    "\n",
    "**Trick 4: `timm` for vision models**\n",
    "- 1000+ pre-trained computer vision models\n",
    "- `pip install timm`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808aec4f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Quick tricks demo\n",
    "\n",
    "# Trick: torchinfo for model summary\n",
    "# !pip install torchinfo\n",
    "# from torchinfo import summary\n",
    "# summary(model, input_size=(32, 4))  # batch_size=32, features=4\n",
    "\n",
    "# Trick: Use repr to see object details\n",
    "print(\"Model architecture:\")\n",
    "print(SimpleNN())\n",
    "\n",
    "# Trick: Quick timing\n",
    "import time\n",
    "start = time.time()\n",
    "# ... your code ...\n",
    "print(f\"Took {time.time() - start:.3f}s\")\n",
    "\n",
    "# Better: Use %%time or %%timeit in Jupyter!\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Small tricks add up to big time savings!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d053aa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4. Dataset Shortcuts\n",
    "\n",
    "**Don't start from scratch:**\n",
    "\n",
    "1. **Papers with Code** - Find datasets and benchmarks\n",
    "2. **Kaggle** - Tons of curated datasets\n",
    "3. **UCI ML Repository** - Classic datasets\n",
    "4. **HEP Data** - Published HEP datasets\n",
    "5. **Zenodo** - Open science data\n",
    "\n",
    "**For HEP specifically:**\n",
    "- CERN Open Data Portal\n",
    "- LHC Olympics datasets\n",
    "- Public collision data\n",
    "\n",
    "**Pro tip:** Start with a small subset! Debug on 1000 events, not 1M.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa8867b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5. The Ultimate Shortcut List\n",
    "\n",
    "**Must-bookmark resources:**\n",
    "\n",
    " **Learning:**\n",
    "- fast.ai course (free, excellent)\n",
    "- PyTorch tutorials (official)\n",
    "- Kaggle Learn (interactive)\n",
    "- Papers with Code (implementations)\n",
    "\n",
    "\ud83d\udee0\ufe0f **Tools:**\n",
    "- GitHub Copilot / Cursor (AI pair programmer)\n",
    "- Paperswithcode.com (find state-of-the-art)\n",
    "- Connected Papers (explore research)\n",
    "\n",
    "\ud83d\udcac **Community:**\n",
    "- PyHEP working group\n",
    "- Scikit-HEP GitHub\n",
    "- ML4Jets workshop materials\n",
    "- Discord/Slack ML communities\n",
    "\n",
    "\ud83c\udf93 **HEP-specific:**\n",
    "- IML (Inter-experimental Machine Learning)\n",
    "- ML4Jets workshops\n",
    "- PyHEP workshops\n",
    "- IRIS-HEP training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d0378",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary: Your ML Toolkit\n",
    "\n",
    "## Quick Reference Guide\n",
    "\n",
    "### For Beginners:\n",
    "1. **Start here:** Scikit-learn for classical ML, Keras for deep learning\n",
    "2. **Read data:** uproot for ROOT files\n",
    "3. **Track experiments:** W&B (free for academics!)\n",
    "4. **Learn:** fast.ai course, official PyTorch tutorials\n",
    "\n",
    "### For Intermediate Users:\n",
    "1. **Framework:** PyTorch or PyTorch Lightning\n",
    "2. **Data:** uproot + awkward array\n",
    "3. **Optimization:** Optuna\n",
    "4. **Deployment:** ONNX\n",
    "5. **Code quality:** pytest, ruff, GitHub Actions\n",
    "\n",
    "### For Advanced Users:\n",
    "1. **Speed:** JAX for compute-intensive tasks\n",
    "2. **Scale:** HTCondor or cloud (SageMaker)\n",
    "3. **Hardware:** hls4ml for FPGAs\n",
    "4. **Tools:** Custom pipelines with all the above\n",
    "\n",
    "### Universal Tips:\n",
    "- Use version control (git)\n",
    "- Write tests (pytest)\n",
    "- Log experiments (W&B/MLflow)\n",
    "- Document your code\n",
    "- Start small, scale up\n",
    "- Leverage pre-trained models (Hugging Face)\n",
    "- Use LLMs wisely (verify everything!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e8b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Final Thoughts\n",
    "\n",
    "## The ML landscape is vast, but you don't need to know everything\n",
    "\n",
    "**Key takeaways:**\n",
    "\n",
    "1. **Pick tools that fit YOUR needs** - Don't use fancy tools just because they're fancy\n",
    "2. **Start simple, add complexity** - Scikit-learn \u2192 PyTorch \u2192 JAX\n",
    "3. **Steal shamelessly** - Use pre-trained models, copy good code, ask LLMs\n",
    "4. **Automate early** - W&B, GitHub Actions, testing save time in the long run\n",
    "5. **Bridge HEP \u2194 ML** - uproot, awkward, hist make life easier\n",
    "6. **Learn from industry** - Testing, CI/CD, code quality matter\n",
    "7. **Community is key** - PyHEP, ML4Jets, IML, Scikit-HEP\n",
    "\n",
    "---\n",
    "\n",
    "## Most important:\n",
    "\n",
    "### **The best tool is the one you'll actually use.**\n",
    "\n",
    "Perfect code that doesn't exist < Working code that's \"good enough\"\n",
    "\n",
    "---\n",
    "\n",
    "# Questions? \n",
    "\n",
    "Resources:\n",
    "- These slides: [your-repo-link]\n",
    "- Scikit-HEP: https://scikit-hep.org/\n",
    "- PyHEP: https://hepsoftwarefoundation.org/workinggroups/pyhep.html\n",
    "- My contact: [your-contact]\n",
    "\n",
    "**Now go build something cool!** \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "rise": {
   "autolaunch": false,
   "center": false,
   "controls": true,
   "enable_chalkboard": true,
   "height": "100%",
   "hideAddressBar": true,
   "history": true,
   "margin": 0,
   "maxScale": 1.5,
   "minScale": 0.2,
   "previewLinks": false,
   "progress": true,
   "scroll": true,
   "slideNumber": true,
   "start_slideshow_at": "selected",
   "theme": "night",
   "transition": "slide",
   "viewDistance": 3,
   "width": "100%",
   "autoPlayMedia": true,
   "transitionSpeed": "slow",
   "keyboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}